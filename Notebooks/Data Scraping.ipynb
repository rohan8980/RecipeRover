{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3531ec8f-1d39-491c-8c42-17e64c408100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4c379f-9d84-4706-a812-1a257dfe54bd",
   "metadata": {},
   "source": [
    "### Utility functions for scraping recipes from the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b18dbfe1-09fb-4c95-a8d1-1a3de01113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_recipes_from_a_page(page_url):\n",
    "    '''\n",
    "    This function takes recipe page url of the format \"https://www.archanaskitchen.com/recipes/page-{page_number}\"\n",
    "    It fetches metadata of all the recipes present on that page\n",
    "    For each fetched recipe metadata it calls fetch_recipe_data to get details of each recipe\n",
    "    Returns list of lists containing all the recipes of that page\n",
    "    '''\n",
    "    \n",
    "    recipes_page = []\n",
    "    base_url = \"https://www.archanaskitchen.com\" ## required for image link and recipe link\n",
    "    page_no = page_url.split('/')[-1].split('-')[-1]\n",
    "    response = requests.get(page_url).text\n",
    "    page = BeautifulSoup(response, 'lxml') \n",
    "        # print(page.prettify())\n",
    "\n",
    "    # Fetching each recipe's name, imagelink and recipe link from each page \n",
    "    for recipes in page.find_all('div', class_='blogRecipe'):\n",
    "        recipe_data=[]\n",
    "        name = recipes.find('span', itemprop='name').text.strip()\n",
    "        image_link = recipes.find('img', itemprop='image')['src']\n",
    "        recipe_link = recipes.find('a', itemprop='url')['href']\n",
    "\n",
    "        image_link = base_url+image_link\n",
    "        recipe_link = base_url+recipe_link\n",
    "        \n",
    "        # print(page_no, name)\n",
    "        \n",
    "        recipe_data = [page_no, name, image_link, recipe_link]\n",
    "        recipe_data.extend(fetch_recipe_data(recipe_link))\n",
    "        recipes_page.append(recipe_data)\n",
    "\n",
    "    return recipes_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "35fbef3d-6ca0-46f9-b396-2220a9fd4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recipe_data(recipe_url):\n",
    "    '''\n",
    "    This function takes a recipe page url of the format \"https://www.archanaskitchen.com/garlic-knot-recipe\"\n",
    "    From this page it fetches all the recipe details present for the recipe\n",
    "    Returns a list of extracted things for the given recipe\n",
    "    '''\n",
    "    \n",
    "    response = requests.get(recipe_url).text\n",
    "    page = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "    # Extracting recipe title\n",
    "    recipe_title = page.find('h1', class_='recipe-title').text.strip() if page.find('h1', class_='recipe-title') else \"\"\n",
    "    \n",
    "    # Extracting image URL\n",
    "    image_url = page.find('img', itemprop='image')['src'] if page.find('img', itemprop='image') else \"\"\n",
    "    image_url = \"https://www.archanaskitchen.com\" + image_url if image_url else \"\"\n",
    "    \n",
    "    # Extracting other details like cuisine, course, diet, etc.\n",
    "    cuisine = page.find('div', class_='cuisine').find('span', itemprop='recipeCuisine').text.strip() if page.find('div', class_='cuisine') else \"\"\n",
    "    course = page.find('div', class_='course').find('span', itemprop='keywords').text.strip() if page.find('div', class_='course') else \"\"\n",
    "    diet = page.find('div', class_='diet').find('span', itemprop='keywords').text.strip() if page.find('div', class_='diet') else \"\"\n",
    "    equipments = ''.join([equipment.text.strip() for equipment in page.find('div', class_='products').find_all('a')]) if page.find('div', class_='products') else \"\"\n",
    "\n",
    "    # Extracting ratings\n",
    "    rating_value = page.find(\"span\", itemprop=\"ratingValue\").text.strip() if page.find(\"span\", itemprop=\"ratingValue\") else \"\"\n",
    "    rating_count = page.find(\"span\", itemprop=\"ratingCount\").text.strip() if page.find(\"span\", itemprop=\"ratingCount\") else \"\"\n",
    "    best_rating = page.find(\"span\", itemprop=\"bestRating\").text.strip() if page.find(\"span\", itemprop=\"bestRating\") else \"\"\n",
    "    worst_rating = page.find(\"span\", itemprop=\"worstRating\").text.strip() if page.find(\"span\", itemprop=\"worstRating\") else \"\"\n",
    "\n",
    "    # Extracting prep time, cook time, total time, and servings\n",
    "    recipe_timings = page.find('div', class_='RecipeServesTime')\n",
    "    if recipe_timings:\n",
    "        prep_time = recipe_timings.find('span', itemprop='prepTime').find('p').get_text().strip() if recipe_timings.find('span', itemprop='prepTime') else \"\"\n",
    "        cook_time = recipe_timings.find('span', itemprop='cookTime').find('p').get_text().strip() if recipe_timings.find('span', itemprop='cookTime') else \"\"\n",
    "        total_time = recipe_timings.find('span', itemprop='totalTime').find('p').get_text().strip() if recipe_timings.find('span', itemprop='totalTime') else \"\"\n",
    "        servings = recipe_timings.find('span', itemprop='recipeYield').find('p').get_text().split()[0].strip() if recipe_timings.find('span', itemprop='recipeYield') else \"\"\n",
    "    else:\n",
    "        prep_time = cook_time = total_time = servings = \"\"\n",
    "        \n",
    "    # Extracting recipe description\n",
    "    recipe_description = page.find('div', class_='recipedescription').find('span', itemprop='description').text.strip() if page.find('div', class_='recipedescription') else \"\"\n",
    "    \n",
    "    # Extracting ingredients\n",
    "    ingredients_sections = page.find_all('div', class_='recipeingredients')\n",
    "    ingredients = []\n",
    "    for subtitle in ingredients_sections:\n",
    "        ul = subtitle.find_next('ul')\n",
    "        for li in ul.find_all('li', itemprop='ingredients'):\n",
    "            text_parts = list(li.stripped_strings)\n",
    "            if len(text_parts) > 1:\n",
    "                quantity, name, *details = text_parts        \n",
    "                details = ' - ' + ' '.join(details) if details else ''\n",
    "                ing = quantity + ' - ' + name + details if name[0] == ',' else name + ' - ' + quantity + details\n",
    "                ing = ing.replace(',', '').replace('  ',' ')\n",
    "            else:\n",
    "                ing = text_parts[0]\n",
    "        \n",
    "            ingredients.append(ing)\n",
    "    ingredients = '|'.join(ingredients)\n",
    "    \n",
    "    # Extracting instructions\n",
    "    instructions = []\n",
    "    instruction_section = page.find('div', class_='recipeinstructions') if page.find('div', class_='recipeinstructions') else \"\"\n",
    "    if instruction_section:\n",
    "        for item in instruction_section.find_all('li', itemprop='recipeInstructions'):\n",
    "            instructions.append(item.text.strip())\n",
    "        instructions = ' '.join(instructions)\n",
    "    \n",
    "    # print(\"Recipe Title:\", recipe_title, '\\n')\n",
    "    # print(\"Recipe Description:\", recipe_description, '\\n')\n",
    "    # print(\"Ingredients:\", ingredients, '\\n')\n",
    "    # print(\"Instructions:\", instructions, '\\n')\n",
    "    # print(\"Image URL:\", image_url, '\\n')\n",
    "    # print(\"Cuisine:\", cuisine, '\\n')\n",
    "    # print(\"Course:\", course, '\\n')\n",
    "    # print(\"Diet:\", diet, '\\n')\n",
    "    # print(\"Equipments:\", equipments, '\\n')\n",
    "    # print(\"Rating Value:\", rating_value, '\\n')\n",
    "    # print(\"Rating Count:\", rating_count, '\\n')\n",
    "    # print(\"Best Rating:\", best_rating), '\\n')\n",
    "    # print(\"Worst Rating:\", worst_rating, '\\n')\n",
    "    # print(\"Prep Time:\", prep_time, '\\n')\n",
    "    # print(\"Cook Time:\", cook_time, '\\n')\n",
    "    # print(\"Total Time:\", total_time, '\\n')\n",
    "    # print(\"Servings:\", servings, '\\n')\n",
    "\n",
    "    # print([recipe_title, image_url, cuisine, course, diet, equipments, rating_value, rating_count, best_rating, worst_rating, prep_time, cook_time, total_time, servings, recipe_description, ingredients, instructions])\n",
    "    return [recipe_title, image_url, cuisine, course, diet, equipments, rating_value, rating_count, best_rating, worst_rating, prep_time, cook_time, total_time, servings, recipe_description, ingredients, instructions]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6c793a5f-9fe7-4bfd-9a55-bee6b7432834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(start_page, end_page):\n",
    "    '''\n",
    "    This function takes two inputs: start_page and end_page numbers\n",
    "    start_page and end_page denotes the first pagea and the last_page to scrap the recipes from the website\n",
    "    It generates page urls of the format \"https://www.archanaskitchen.com/recipes/page-{page_number}\" for all pages between start and end pages\n",
    "    Calls all_recipes_from_a_page function for each page url and saves result into a list\n",
    "    Results are saved in the csv file (file name contains first and last page)\n",
    "    '''\n",
    "    \n",
    "    all_recipes = []\n",
    "    base_page_link = \"https://www.archanaskitchen.com/recipes/page-\"\n",
    "    file_path = os.path.join(os.getcwd(), '..', 'Data', f'Recipes_{start_page}_to_{end_page}.csv')\n",
    "    url_list = [base_page_link + str(i) for i in range(start_page, end_page + 1)]\n",
    "\n",
    "    ## Traversing each page and all recipes on that page\n",
    "    for url in url_list:\n",
    "        print(url)\n",
    "        recipes_page = all_recipes_from_a_page(url)\n",
    "        all_recipes.extend(recipes_page)\n",
    "\n",
    "    ## Creating Dataframe to save scraped data\n",
    "    columns = ['Page No', 'Recipe Name', 'Image URL', 'Recipe URL', 'Recipe URL Title', 'Image URL Original', 'Cuisine', 'Course', 'Diet', 'Equipments', 'Average Rating', 'Total Ratings', 'Best Rating', 'Worst Rating', 'Prep Time', 'Cook Time', 'Total Time', 'Servings', 'Recipe Description', 'Ingredients', 'Instructions']\n",
    "    df = pd.DataFrame(all_recipes, columns=columns)\n",
    "\n",
    "    ## Saving batch data to a file\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055480b-a982-4fe5-8774-1eec4ffc9a23",
   "metadata": {},
   "source": [
    "### Running the batches with batch size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "39603311-2d1b-4d1c-a3a7-5ba25922c4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.archanaskitchen.com/recipes/page-91\n",
      "https://www.archanaskitchen.com/recipes/page-92\n",
      "https://www.archanaskitchen.com/recipes/page-93\n",
      "https://www.archanaskitchen.com/recipes/page-94\n",
      "https://www.archanaskitchen.com/recipes/page-95\n",
      "https://www.archanaskitchen.com/recipes/page-96\n",
      "https://www.archanaskitchen.com/recipes/page-97\n",
      "https://www.archanaskitchen.com/recipes/page-98\n",
      "https://www.archanaskitchen.com/recipes/page-99\n",
      "https://www.archanaskitchen.com/recipes/page-100\n"
     ]
    }
   ],
   "source": [
    "first_page = 91  #1\n",
    "last_page = 100   #337\n",
    "batch_size = 10\n",
    "\n",
    "for i in range(first_page-1, last_page, batch_size):\n",
    "    start_page = i+1\n",
    "    end_page = min(i + batch_size, last_page)\n",
    "    #print(start_page, end_page)\n",
    "    process_batch(start_page, end_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d3e6d-541d-402e-b7f8-cfc97ac5e76b",
   "metadata": {},
   "source": [
    "### Merging into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dedf6773-067a-4b4f-83c5-c15ab562a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.path.join(os.getcwd(), '..', 'Data')\n",
    "save_path = os.path.join(directory_path, 'Recipes.csv')\n",
    "\n",
    "\n",
    "# Read each CSV file into a DataFrame and concat them\n",
    "df_all = pd.DataFrame()\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "csv_files.sort(key=lambda filename: int(re.search(r'\\d+', filename).group()))\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Save to the file\n",
    "df_all.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cb530-c1f2-44c7-bf5c-9d0674700567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8f2a8-61c4-42d7-a7ae-5abddcf234ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f147dfdf-fade-430e-93b1-53b2c66d20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.path.join(os.getcwd(), '..', 'Data')\n",
    "batches_path = os.path.join(directory_path, 'Batches')\n",
    "os.makedirs(batches_path, exist_ok=True)\n",
    "\n",
    "for file in csv_files:\n",
    "    if file.startswith('Recipes_'):\n",
    "        cur_path = os.path.join(directory_path, file)\n",
    "        mov_path = os.path.join(batches_path, file)\n",
    "        os.rename(cur_path, mov_path)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
